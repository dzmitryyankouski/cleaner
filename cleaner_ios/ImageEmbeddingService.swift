//
//  ImageEmbeddingService.swift
//  cleaner_ios
//
//  Created by Dmitriy Yankovskiy on 06/09/2025.
//

import Foundation
import Vision
import CoreML
import UIKit

class ImageEmbeddingService: ObservableObject {
    @Published var isProcessing = false
    @Published var embedding: [Float]?
    @Published var errorMessage: String?
    
    private var mobileClipModel: MLModel?
    private var compiledModelURL: URL?
    
    init() {
        // –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å –≤ Bundle –µ—Å–ª–∏ –µ—ë —Ç–∞–º –Ω–µ—Ç
        loadMobileClipModel()
    }

    
    private func loadMobileClipModel() {
        print("üîç –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å MobileCLIP...")

        // –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ Bundle (–µ—Å–ª–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∞)
        if let modelURL = Bundle.main.url(forResource: "mobileclip_s0_image", withExtension: "mlmodelc") {
            do {
                mobileClipModel = try MLModel(contentsOf: modelURL)
                print("‚úÖ –ú–æ–¥–µ–ª—å MobileCLIP –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ Bundle!")
                return
            } catch {
                print("‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –∏–∑ Bundle: \(error)")
            }
        }
        
        // –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ
        errorMessage = "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ —Å–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞–Ω–Ω—É—é –º–æ–¥–µ–ª—å MobileCLIP"
        print("‚ùå –í—Å–µ —Å–ø–æ—Å–æ–±—ã –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å")
    }
    
    func generateEmbedding(from image: UIImage) {
        isProcessing = true
        errorMessage = nil
        
        guard let mobileClipModel = mobileClipModel else {
            errorMessage = "–ú–æ–¥–µ–ª—å MobileCLIP –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
            isProcessing = false
            return
        }
        
        guard let cgImage = image.cgImage else {
            errorMessage = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
            isProcessing = false
            return
        }
        
        // –ò—Å–ø–æ–ª—å–∑—É–µ–º Vision framework —Å –º–æ–¥–µ–ª—å—é MobileCLIP
        let request = VNCoreMLRequest(model: try! VNCoreMLModel(for: mobileClipModel)) { [weak self] request, error in
            DispatchQueue.main.async {
                self?.isProcessing = false
                
                if let error = error {
                    self?.errorMessage = "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: \(error.localizedDescription)"
                    return
                }
                
                guard let results = request.results as? [VNCoreMLFeatureValueObservation],
                      let firstResult = results.first,
                      let multiArray = firstResult.featureValue.multiArrayValue else {
                    self?.errorMessage = "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–∏–Ω–≥"
                    return
                }
                
                // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º MLMultiArray –≤ –º–∞—Å—Å–∏–≤ Float
                let embedding = self?.convertMultiArrayToFloatArray(multiArray) ?? []
                self?.embedding = embedding
            }
        }
        
        // –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        request.imageCropAndScaleOption = .centerCrop
        
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                try handler.perform([request])
            } catch {
                DispatchQueue.main.async {
                    self.isProcessing = false
                    self.errorMessage = "–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞: \(error.localizedDescription)"
                }
            }
        }
    }
    
    private func convertMultiArrayToFloatArray(_ multiArray: MLMultiArray) -> [Float] {
        // –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º MLMultiArray –≤ –º–∞—Å—Å–∏–≤ Float
        let count = multiArray.count
        var result = [Float](repeating: 0, count: count)
        
        for i in 0..<count {
            result[i] = Float(truncating: multiArray[i])
        }
        
        return result
    }
    
    func getEmbeddingAsString() -> String {
        guard let embedding = embedding else { return "–≠–º–±–µ–¥–∏–Ω–≥ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω" }
        
        let formattedValues = embedding.map { String(format: "%.4f", $0) }
        return "–≠–º–±–µ–¥–∏–Ω–≥ (\(embedding.count) –∏–∑–º–µ—Ä–µ–Ω–∏–π):\n" + formattedValues.joined(separator: ", ")
    }
    
    func getEmbeddingStatistics() -> String {
        guard let embedding = embedding else { return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö" }
        
        let min = embedding.min() ?? 0
        let max = embedding.max() ?? 0
        let mean = embedding.reduce(0, +) / Float(embedding.count)
        
        return """
        –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: \(embedding.count)
        –ú–∏–Ω–∏–º—É–º: \(String(format: "%.4f", min))
        –ú–∞–∫—Å–∏–º—É–º: \(String(format: "%.4f", max))
        –°—Ä–µ–¥–Ω–µ–µ: \(String(format: "%.4f", mean))
        """
    }
}

// MobileCLIP S0 –º–æ–¥–µ–ª—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∏ –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é
// –ú–æ–¥–µ–ª—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–µ—Ä–≤–∏—Å–∞
// –≠–º–±–µ–¥–∏–Ω–≥–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Vision framework –∏ Core ML
